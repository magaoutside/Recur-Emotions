{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список эмоций, которые будет распознавать модель\n",
    "emotion_labels = ['Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise', 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для записи логов в файл\n",
    "def log_emotion(emotion, confidence):\n",
    "    log_dir = \"logs\"\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)  # Создаем папку logs, если она не существует\n",
    "    \n",
    "    log_file = os.path.join(log_dir, \"cameralog.txt\")\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Получаем текущее время\n",
    "    log_entry = f\"{current_time} - {emotion} - {confidence:.2f}%\\n\"\n",
    "    \n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(log_entry)  # Записываем лог в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для предсказания эмоции на изображении\n",
    "def predict_emotion(frame, model):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        face = gray[y:y + h, x:x + w]\n",
    "        face_resized = cv2.resize(face, (48, 48))\n",
    "        face_normalized = face_resized / 255.0\n",
    "        face_reshaped = np.expand_dims(face_normalized, axis=0)\n",
    "        face_reshaped = np.expand_dims(face_reshaped, axis=-1)\n",
    "        emotion_prediction = model.predict(face_reshaped)\n",
    "        max_index = np.argmax(emotion_prediction[0])\n",
    "        emotion = emotion_labels[max_index]\n",
    "        confidence = np.max(emotion_prediction[0]) * 100\n",
    "        \n",
    "        # Логируем эмоцию и точность\n",
    "        log_emotion(emotion, confidence)\n",
    "        \n",
    "        # Добавление текста с эмоцией на изображение\n",
    "        cv2.putText(frame, f\"{emotion} {confidence:.2f}%\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для включения камеры и отображения эмоций в реальном времени\n",
    "def start_camera():\n",
    "    try:\n",
    "        # Загрузка модели для распознавания эмоций\n",
    "        model = tf.keras.models.load_model(\"model/model.h5\")\n",
    "        print(\"Модель успешно загружена.\")\n",
    "    except Exception as e:\n",
    "        # Обработка ошибки загрузки модели\n",
    "        print(f\"Ошибка загрузки модели: {e}\")\n",
    "        return\n",
    "\n",
    "    # Инициализация видеозахвата с камеры\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Установка параметров камеры\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)  # Ширина кадра\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)  # Высота кадра\n",
    "    cap.set(cv2.CAP_PROP_FPS, 60)  # Частота кадров\n",
    "\n",
    "    # Проверка применённых настроек камеры\n",
    "    print(\"Установленные параметры камеры:\")\n",
    "    print(\"Ширина кадра:\", cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    print(\"Высота кадра:\", cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(\"FPS камеры:\", cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # Проверка, открыта ли камера\n",
    "    if not cap.isOpened():\n",
    "        print(\"Ошибка: камера недоступна.\")\n",
    "        return\n",
    "\n",
    "    # Сообщение о успешном подключении камеры\n",
    "    print(\"Камера подключена. Нажмите 'q' для выхода.\")\n",
    "    \n",
    "    try:\n",
    "        # Основной цикл для захвата и обработки кадров\n",
    "        while True:\n",
    "            # Захват кадра с камеры\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # Проверка успешности захвата кадра\n",
    "            if not ret:\n",
    "                print(\"Ошибка захвата кадра. Проверьте подключение камеры.\")\n",
    "                break\n",
    "\n",
    "            # Предсказание эмоции на текущем кадре\n",
    "            frame_with_emotions = predict_emotion(frame, model)\n",
    "            \n",
    "            # Отображение изображения с наложенными эмоциями\n",
    "            cv2.imshow('Emotion Recognition', frame_with_emotions)\n",
    "\n",
    "            # Выход из цикла по нажатию клавиши 'q'\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                print(\"Выход.\")\n",
    "                break\n",
    "    except Exception as e:\n",
    "        # Обработка ошибок во время работы камеры\n",
    "        print(f\"Ошибка во время работы камеры: {e}\")\n",
    "    finally:\n",
    "        # Освобождение ресурсов камеры и закрытие окон\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель успешно загружена.\n",
      "Установленные параметры камеры:\n",
      "Ширина кадра: 1920.0\n",
      "Высота кадра: 1080.0\n",
      "FPS камеры: 60.0\n",
      "Камера подключена. Нажмите 'q' для выхода.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Выход.\n"
     ]
    }
   ],
   "source": [
    "# Запуск камеры\n",
    "if __name__ == \"__main__\":\n",
    "    start_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import load_model\n",
    "# import os\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Список эмоций, которые будет распознавать модель\n",
    "# emotion_labels = ['Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise', 'Neutral']\n",
    "\n",
    "# # Функция для записи логов в файл\n",
    "# def log_emotion(emotion, confidence):\n",
    "#     log_dir = \"logs\"\n",
    "#     if not os.path.exists(log_dir):\n",
    "#         os.makedirs(log_dir)  # Создаем папку logs, если она не существует\n",
    "    \n",
    "#     log_file = os.path.join(log_dir, \"cameralog.txt\")\n",
    "#     current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Получаем текущее время\n",
    "#     log_entry = f\"{current_time} - {emotion} - {confidence:.2f}%\\n\"\n",
    "    \n",
    "#     with open(log_file, \"a\") as f:\n",
    "#         f.write(log_entry)  # Записываем лог в файл\n",
    "\n",
    "# # Функция для предсказания эмоции на изображении\n",
    "# def predict_emotion(frame, model):\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "#     faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "#     for (x, y, w, h) in faces:\n",
    "#         face = gray[y:y + h, x:x + w]\n",
    "#         face_resized = cv2.resize(face, (48, 48))\n",
    "#         face_normalized = face_resized / 255.0\n",
    "#         face_reshaped = np.expand_dims(face_normalized, axis=0)\n",
    "#         face_reshaped = np.expand_dims(face_reshaped, axis=-1)\n",
    "#         emotion_prediction = model.predict(face_reshaped)\n",
    "#         max_index = np.argmax(emotion_prediction[0])\n",
    "#         emotion = emotion_labels[max_index]\n",
    "#         confidence = np.max(emotion_prediction[0]) * 100\n",
    "        \n",
    "#         # Логируем эмоцию и точность\n",
    "#         log_emotion(emotion, confidence)\n",
    "        \n",
    "#         # Добавление текста с эмоцией на изображение\n",
    "#         cv2.putText(frame, f\"{emotion} {confidence:.2f}%\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "#         cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "#     return frame\n",
    "\n",
    "# # Функция для включения камеры и отображения эмоций в реальном времени\n",
    "# def start_camera():\n",
    "#     try:\n",
    "#         # Загрузка модели для распознавания эмоций\n",
    "#         model = tf.keras.models.load_model(\"model/model.h5\")\n",
    "#         print(\"Модель успешно загружена.\")\n",
    "#     except Exception as e:\n",
    "#         # Обработка ошибки загрузки модели\n",
    "#         print(f\"Ошибка загрузки модели: {e}\")\n",
    "#         return\n",
    "\n",
    "#     # Инициализация видеозахвата с камеры\n",
    "#     cap = cv2.VideoCapture(0)\n",
    "\n",
    "#     # Установка параметров камеры\n",
    "#     cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)  # Ширина кадра\n",
    "#     cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)  # Высота кадра\n",
    "#     cap.set(cv2.CAP_PROP_FPS, 60)  # Частота кадров\n",
    "\n",
    "#     # Проверка применённых настроек камеры\n",
    "#     print(\"Установленные параметры камеры:\")\n",
    "#     print(\"Ширина кадра:\", cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     print(\"Высота кадра:\", cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#     print(\"FPS камеры:\", cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "#     # Проверка, открыта ли камера\n",
    "#     if not cap.isOpened():\n",
    "#         print(\"Ошибка: камера недоступна.\")\n",
    "#         return\n",
    "\n",
    "#     # Сообщение о успешном подключении камеры\n",
    "#     print(\"Камера подключена. Нажмите 'q' для выхода.\")\n",
    "    \n",
    "#     try:\n",
    "#         # Основной цикл для захвата и обработки кадров\n",
    "#         while True:\n",
    "#             # Захват кадра с камеры\n",
    "#             ret, frame = cap.read()\n",
    "            \n",
    "#             # Проверка успешности захвата кадра\n",
    "#             if not ret:\n",
    "#                 print(\"Ошибка захвата кадра. Проверьте подключение камеры.\")\n",
    "#                 break\n",
    "\n",
    "#             # Предсказание эмоции на текущем кадре\n",
    "#             frame_with_emotions = predict_emotion(frame, model)\n",
    "            \n",
    "#             # Отображение изображения с наложенными эмоциями\n",
    "#             cv2.imshow('Emotion Recognition', frame_with_emotions)\n",
    "\n",
    "#             # Выход из цикла по нажатию клавиши 'q'\n",
    "#             if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                 print(\"Выход.\")\n",
    "#                 break\n",
    "#     except Exception as e:\n",
    "#         # Обработка ошибок во время работы камеры\n",
    "#         print(f\"Ошибка во время работы камеры: {e}\")\n",
    "#     finally:\n",
    "#         # Освобождение ресурсов камеры и закрытие окон\n",
    "#         cap.release()\n",
    "#         cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
